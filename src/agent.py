from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
from langgraph.prebuilt import create_react_agent
from tools import SearchToolKit
from utility import load_system_prompt
from langgraph.checkpoint.memory import MemorySaver
from typing import Generator, Dict, Any
from langchain_core.runnables import RunnableConfig
from typing import Optional
from langchain_openai import ChatOpenAI
from os import getenv
class MovieSearchAgent:
    def __init__(self, model_name: str = "gpt-4o-mini", model_provider: str = "openai", search_engine: str = "google"):
        load_dotenv()
        
        # Initialize components
        self.memory = MemorySaver()
        self.search_toolkit = SearchToolKit(search_engine)
        self.tools = self.search_toolkit.get_tools()
        
        # Initialize model and agent
        # Check if OpenRouter environment variables are available
        openrouter_api_key = getenv("OPENROUTER_API_KEY")
        openrouter_base_url = getenv("OPENROUTER_BASE_URL")
        
        # Configure model with OpenRouter if available, otherwise use default OpenAI setup
        if openrouter_api_key and openrouter_base_url:
            self.model = ChatOpenAI(
                model_name=model_name,
                openai_api_key=openrouter_api_key,
                openai_api_base=openrouter_base_url,
            )
        else:
            self.model = ChatOpenAI(
                model_name=model_name,
            )
        self.system_message = load_system_prompt()
        self.agent_executor = create_react_agent(
            self.model,
            self.tools,
            prompt=self.system_message,
            checkpointer=self.memory
        )

    def get_complete_response(self, user_input: str, config: RunnableConfig) -> Dict[str, Any]:
        """
        Process user input and return the complete final response from the agent.
        
        This method waits for the entire agent processing to complete before returning
        the final result, making it suitable for non-streaming interfaces.
        
        Args:
            user_input (str): The user's input message to be processed by the agent.
            config (RunnableConfig): Configuration settings for invoking the agent.
            
        Returns:
            Dict[str, Any]: The complete response from the agent, including all messages and steps.
        """
        return self.agent_executor.invoke(
            {"messages": [HumanMessage(content=user_input)]},
            config=config
        )

    def get_streaming_response(self, user_input: str, config: Optional[RunnableConfig] = None) -> Generator[Dict[str, Any], None, None]:
        """
        Process user input and yield incremental response updates as they become available.
        
        This method is designed for real-time UI updates, allowing the interface to show
        partial results as they are generated by the agent.
        
        Args:
            user_input (str): The user's input message
            config (Optional[RunnableConfig]): Optional configuration for the response stream
        Returns:
            Generator[Dict[str, Any], None, None]: A generator yielding incremental response steps
        """
        return self.agent_executor.stream(
            {"messages": [HumanMessage(content=user_input)]},
            stream_mode="values",
            config=config
        )

def run_cli():
    """Run the agent in CLI mode"""
    
    if getenv("OPENAI_API_KEY") is None and getenv("OPENROUTER_API_KEY") is None:
        print("OPENAI_API_KEY or OPENROUTER_API_KEY is not set. Please set it in the environment variables.")
        return
    
    agent = MovieSearchAgent(model_name="gpt-4o-mini", model_provider="openai", search_engine="duckduckgo")
    
    print("Movie Search Agent - Interactive Chat")
    print("Type 'exit' or 'quit' to end the conversation")
    print("-" * 50)

    while True:
        try:
            user_input = input("\nYou: ").strip()
            
            if user_input.lower() in ['exit', 'quit']:
                print("\nGoodbye!")
                break
                
            if not user_input:
                continue
                
            print("\nAgent: ", end='', flush=True)
            for step in agent.get_streaming_response(user_input):
                step["messages"][-1].pretty_print()
                
        except KeyboardInterrupt:
            print("\n\nExiting...")
            break
        except Exception as e:
            print(f"\nAn error occurred: {str(e)}")

if __name__ == "__main__":
    run_cli()